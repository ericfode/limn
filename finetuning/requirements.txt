# Limn Finetuning Requirements
# ==============================

# Core training dependencies
torch>=2.0.0
transformers>=4.30.0
datasets>=2.12.0
peft>=0.4.0
accelerate>=0.20.0

# For QLoRA (8-bit training)
bitsandbytes>=0.39.0

# Data processing
numpy>=1.24.0
pandas>=2.0.0

# Evaluation
scikit-learn>=1.3.0

# Optional: for monitoring
# tensorboard>=2.13.0
# wandb>=0.15.0
